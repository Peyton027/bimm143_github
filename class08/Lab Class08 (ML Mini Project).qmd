---
title: "Class 8 Breast Cancer Analysis Mini Project"
author: "Peyton Chiu (PID:A18145937)"
format: pdf
toc: true
---

## Background 

The goal of this mini-project is to explore a complete analysis using the unsupervised learning techniques covered in class.

The data itself comes from the Wisconsin Breast Cancer Diagnostic Data Set first reported by K. P. Benne and O. L. Mangasarian: “Robust Linear Programming Discrimination of Two Linearly Inseparable Sets”.

Values in this data set describe characteristics of the cell nuclei present in digitized images of a fine needle aspiration (FNA) of a breast mass.

## Data import

Data was downloaded from the class website as a CSV file

```{r}


wisc.df <- read.csv("WisconsinCancer.csv", row.names=1)
head(wisc.df)
```

The first column "diagnosis" is the expert opinion on the sample (i.e. FNA)

```{r}
wisc.df$diagnosis

```

Remove the diagnosis from the data for subsequent analysis 
```{r}
wisc.data <- wisc.df[,-1]
dim(wisc.data)
```

Store the diagnosis as a vector to use later when we compare our results to those from experts in the field


```{r}
diagnosis <-factor(wisc.df$diagnosis)
```



>Q1. How many observations are in this dataset?

There are `r nrow(wisc.data)` observations/patients in the data set 

>Q2. How many of the observations have a malignant diagnosis?

```{r}
table(wisc.df$diagnosis)
```
212 of the observations have a malignant diagnosis

>Q3. How many variables/features in the data are suffixed with _mean?

```{r}
#colnames(wisc.data)

length(grep("_mean",colnames(wisc.data)))
```

There are 10 variables in the data suffixed with _mean



## Principal Component Analysis 

The `prcomp` function to do PCA has `scale=False` default. In general we nearly always want to set this to TRUE so our analysis is dominated by columns/variables in our dataset that have high standard deviation and mean when compared to others for instance because of differences in scale

```{r}
wisc.pr <- prcomp(wisc.data, scale = TRUE )
summary(wisc.pr)

```

The main PC result figure is called a "score plot" or "PC plot" or "ordination plot" 

```{r}
library(ggplot2)
ggplot(wisc.pr$x) +
  aes(PC1, PC2, col=diagnosis) +
        geom_point()
          

```





>Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

44.27% of the original variance is captured by PC1


>Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

You need 3 PCs to describe at least 70% of the original variance 


>Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

You need at least 7 PCs to describe at least 90% of the original variance 


## Interpreting PCA results 

```{r}
biplot(wisc.pr)
```

>Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

The data is all clustered together with all the text overlapping each other. The graph is hard to understand because of this. 

```{r}
plot( wisc.pr$x, col = diagnosis , 
     xlab = "PC1", ylab = "PC2")
```

```{r}
plot( wisc.pr$x[,3], col = diagnosis , 
     xlab = "PC1", ylab = "PC2")



```











## PCA Screen -plot
A plot of how much variance each PC captures. We can get this from `wisc.pr$sdev` or from the output of `summary(wisc.pr)`

```{r}
##var.tbl
```

```{r}
##var <- var.tbl$importance[2,]
##cum.var <- var.tbl$importance[3,]

##plot(var, typ ="b", ylab = "Percent Variance Captured",
  ##   xlab ="PC Number")
```

```{r}
##plot(cum.var, typ ="b", ylab = "Percent Variance Captured",
    ## xlab ="PC Number")
```


>Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation["concave.points_mean", "PC1"]
```



> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

```{r}
summary(wisc.pr)
```

You need at least 5 PCs to explain 80% of the variance 


## Hierarchial Clustering 

Just clustering the original data is not very informative or helpful

```{r}

data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
##wisc.hclust <- hclust(data.dist,)


```


```{r}
##table(cutree(wisc.hclust, k=4))
```

```{r}
##table(cutree(wisc.hclust, diagnosis))
```



## Combining Methods (Clustering and PCA)

Clustering the orginal data was not very effectvive. The PCA results looked promising. Here we combine these methods by clustering from our PCA results. In other words 'clustering in PC space' 



```{r}
## Take the first 3 PCs 
dist.pc<- dist(wisc.pr$x[,1:3])
wisc.pr.hclust <-hclust(dist.pc, method = "ward.D2")
```

View the tree
```{r}
plot(wisc.pr.hclust)
abline(h=70, col ="red")
```

To get our clustering membership vector (i.e. our main clustering results) we "cut" the tree at a desired height or to yield a desired  height or to yield a destied number of "k" groups

```{r}
grps <- cutree(wisc.pr.hclust, h=70)
table(grps)
```


How does this clustering grps compare to the expert 

```{r}
table(grps, diagnosis)
```


Sensitivity is TP/(TP+FN)
Specificity is TN/(TN +FN)

## 7. Prediction 
We can use our PCA model for prediction with new input patient samples 



